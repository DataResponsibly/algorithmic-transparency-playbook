---
title: Defining algorithmic transparency
---

## How do we define "transparency?"

There is no single definition for **transparency.** For the purposes of this course, we define transparency as **“the ability of a human to understand an algorithmic system’s decision-making.”** This is a very broad definition, and may have different meanings depending on the context. For example, in one context, transparency may mean that people are able to anticipate what decision an algorithmic system would make, and in another context it could mean knowing the list of factors that are taken into account by the algorithmic system.

As an analogy, consider that there are many ways to understand how a television set works. You can understand aspects like,
- What it does (ex. displays a picture)
- How to work it (ex. using the remote)
- How it works to the extent that you could fix it if it breaks or reconstruct it from the ground up

This type of tiered understanding can be applied to an algorithmic decision system, where each tier is a component of transparency.

> It’s important to note that data scientists, researchers, managers, and even policymakers use a variety of definitions (and often interchange them) to speak about transparency. For example, researchers and data scientists most commonly use the term **explainability** to mean transparency, but other terms include _interpretability, understandability, intelligibility, comprehensibility, accountability, traceability, and legibility_.

> Having many different definitions is useful for distinguishing nuanced aspects of transparency in a technical setting, but for the purposes of this course you only need to know that all of these definitions refer to **different aspects of human understanding of an algorithmic system.**