---
title: Becoming a Transparency Influencer
---

## When algorithms already exist or being built

Why don't organizations maek algorithmic transparency a priority?

There are several key reasons why organizations avoid or neglect algorithmic transparency. In this section, we disccuss these reasons, and importantly offer a rebuttal as to why they are inadequate justifaction for not pursuing transparency. These rebuttals can be useful to help you become a **transparency influencer** within your organization, and create meaningful change towards having a more transparent, ethical approach to algorihtms.

### Claim: implementing transparency means sacrificng accuracy

This is not true.

Many managers are concerned that implementing transparency means reducing the sophistication of their algorithmic systems, thereby decreasing their efficiency and accuracy. For example, in the context of algorithmic hiring, some managers erroneously believe that making the resume screener more transparent means it will perform worse.

However, recent research has challenged this idea. First, as described previously, there are a number of transparency tools that can be used to "open up" even the most complex, sophisticated black-box systems. Second, there is a growing number of case studies showing that under many conditions, simpler, more transparent algorithmic systems can perform the same (or even better than) complex systems. Overall, implementing transparency does not necessarily result in sacrificing efficiency–it’s not that simple!

### Claim: transparency means more costs

While its true that are some costs to implementing algorithmic transparency, these costs are often grossly overstated --- especially when compared to the potential costs of _not_ implementing transparency. Later in this course, we will detail the exact process and types of conversations one needs to have to implement transparency.

Notably, what is often _understated_ is the costs that are saved through algorithmic transparency. Transparency can be used to avoid performance risks like algorithmic errors, security risks, control risks like rogue outcomes and unintended consequences, economic risks, ethical risks, and societal risks like unfair outcomes for underprivileged or marginalized communities. All of these risks can have costly consequneces, like poor algorithms leading to worse business decisions or public relations risks, which can be greatly mitigated by using transpranecy.

> *Case study:* In 2019, Meta (then Facebook) recieved a record-breaking FTC fine of $5 billion for violations related to privacy, accountability and transparency. Despite the fine being substantial, the true penalty is that Meta is now required to hire compliance officers that activetely participate and oversee business decisions at _all levels of the company_ --- a cost that is even more impactful than the $5 billion fine. This case study illustrates a key point: *ignoring transparency may save costs in the short-run, but leaves an organization vulnerable to catastrophic risks in the future.*

### Claim: transparency means open-sourcing

Algorithmic transparency is **not** the same as ``open-sourcing'' technologies. While providing the source code for an algorithm does offer some transparency into how it works, *it is not necessary for transparency.*

In fact, in many cases, open-sourcing is an insufficinet or misguided attempt at transparency for two reasons: first, the source code is not useful for laymen or any non-technical stakeholders of the algorithm in helping them understand how it works. Second, the source code for an algorithm is only one component of a much larger technical ecosystem. Without the data that is used by the algorithm or the technical infrastructure that supports it, the source code may be completely useless.

Note that in some situations open-sourcing _can_ be a component of transparency, but it is by no means required.

### Claim: transparency means a loss of Intellectual Property (IP)

Protecting IP is often a major concern for small startups, or companies whose main competetive advantage is due to the IP of their algorithms. It would be untruthful to say that transparency is not, at least in some ways, in conflict with protecting IP.

However, we forward the claim that _it is possible_ to implement . 

- *Creating transparency for different pieces of elements of your algorithm, where those sum of those peices are insufficient to full reconstruct your IP.* It is not uncommon that an algorithm is made up of multiple layers of decision making, or uses tens (or hundreds) of attributes, factors, and inputs to make decisions. Perhaps it is possible to implement transparency sourrundings specific layers of the algorithm, or focusing on just 3-5 factors (or broad categories of factors).
- *Using Differential Privacy.* Differential privacy is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset, while withholding the true information contained in a dataset.

### Claim: transparency means sacrificng privacy

Privacy in the context of algorithmic systems is generally concerned with protecting sensitive data that the organization has collected. We want to make it clear that **it is a complete myth** that one has to sacrafice the privacy of their data to offer transparency. It is _never_ necessary to expose sensitive or proprietary data to ensure algorithmic transparency. In fact, this is exactly the objective of *Differential Privacy.*

> Differential privacy is a large --- and sometimes comlex --- topic, but a primer can be found [here](https://privacytools.seas.harvard.edu/differential-privacy).

### Claim: transparency means our algorithms are vunerable to stratetigc manipulation by our users (being gamed)

The bad news is that even without algorithmic transaprency, strategic manipulation of algorithms by users is widespread. For example, in the hiring space, some candidates add invisible keywords in white text to the bottom of their resumes to trick algorithms into scoring their application higher. Another more prevelant example is Search Engine Opmitization (SEO), which is the process of trying to "game" your webpage to the top of the serach results.

In light of this, transparency may actually be an _answer_ to strategic manipulation. If an organization is more open with users, it increases trust, which could decrease the desire to abuse algorithms.

## When algorithmic tools are or will be procured

Many organizations, especially in governmental or intergovernmental organizations, choose to procure their algorithmic tools instead of building them in-house. This posess a unique challenge, because because it may be beyond the agency or control of your orgnization to implement transparency for these tools. For this reason _agency to implement transparency_ is an important consideration to weigh when choosing to procure algorithmic tools.

In light of this, we have also drafted this list of probing questions that can be asked to organizations providing algorithmic tools that will help open the conversation around transparency:

- What are your values around algorithmic transparency?
- What considerations to transparency have you implemented in the tool being considered?
- If we require additional transparency considerations, are you able to implement them?
- What are the differences in algorithmic transparency in the selling organization as compared to procuring organization? In other words, what do you know about how the tool works that those who buy it do not?
- How much transparency can we pass onwards to those affected by the tool?