---
title: Barriers to Transparency and Becoming an Influencer
---

## Barriers to Algorithmic Transparency

There are several key reasons why organizations avoid or neglect algorithmic transparency, which are presented below. Importantly, we also offer a rebuttal for each reason, and why they are inadequate justifaction for not pursuing transparency. These rebuttals can be useful to help you become a **transparency influencer** within your organization, and create meaningful change towards having a more transparent, ethical approach to algorihtms.

### Claim: implementing transparency means sacrificng accuracy

This is not true.

Many managers are concerned that implementing transparency means reducing the sophistication of their algorithmic systems, thereby decreasing their efficiency and accuracy. However, recent research has challenged this idea. First, as described previously, there are a number of transparency tools that can be used to "open up" even the most complex, sophisticated black-box systems. Second, there is a growing number of case studies showing that under many conditions, simpler, more transparent algorithmic systems can perform the same (or even better than) complex systems. Overall, implementing transparency does not necessarily result in sacrificing efficiency–it’s not that simple!

### Claim: transparency means more costs

While its true that are some costs to implementing algorithmic transparency, these costs are often grossly overstated. Generally, implementing transparency will mean conversations with stakeholders and minor additional work for engineers building the algorithmic system.

Notably, what is often _understated_ is the costs that are saved through algorithmic transparency. Earlier we mentioned risks related to algorithmic decision systems such as performance risks like algorithmic errors, security risks, control risks like rogue outcomes and unintended consequences, economic risks, ethical risks, and societal risks like unfair outcomes for underprivileged or marginalized communities. All of these risks can have costly consequneces, like poor algorithms leading to worse business decisions or public relations risks, which can be greatly mitigated by using transpranecy.

### Claim: transparency means open-sourcing and a loss of intellectual property

Algorithmic transparency is **not** the same as ``open-sourcing'' technologies. While providing the source code for an algorithm does offer some transparency into how it works, it is not necessary.

In fact, in many cases, open-sourcing is an insufficinet or misguided attempt at transparency for two reasons: first, the source code is not useful for laymen or any non-technical stakeholders of the algorithm in helping them understand how it works. Second, the source code for an algorithm is only one component of a much larger technical ecosystem. Without the data that is used by the algorithm or the technical infrastructure that supports it, the source code may be completely useless.

Note that in some situations open-sourcing _can_ be a component of transparency, but it is by no means required.

### Claim: transparency means sacrificng privacy

Privacy in the context of algorithmic systems is generally concerned with protecting sensitive data that the organization has collected. We want to make it clear that **it is a complete myth** that one has to sacrafice the privacy of their data to offer transparency It is _never_ necessary to expose sensitive or proprietary data to ensure algorithmic transparency. In this course, we will go several ideas or methods that can be used to ensure transparency for a system without violating privacy.

### Claim: transparency means our algorithms are vunerable to stratetigc manipulation by our users (being gamed)

The bad news is that even without algorithmic transaprency, strategic manipulation of algorithms by users is widespread. For example, in the hiring space, some candidates add invisible keywords in white text to the bottom of their resumes to trick algorithms into scoring their application higher. Another more prevelant example is Search Engine Opmitization (SEO), which is the process of trying to "game" your webpage to the top of the serach results.

In light of this, transparency may actually be an _answer_ to strategic manipulation. If an organization is more open with users, it increases trust, which likely will decrease the desire to abuse algorithms.
