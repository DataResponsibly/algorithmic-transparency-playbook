---
title: Core Aspects of Transparency
---

## Core Aspects of Transparency
_Suggested time: 10 minutes_

### The critical importance of algorithmic transparency

- **Transparency can play a critical role in avoiding the significant risks and harms associated with algorithmic decision systems.** These risks include performance risks like algorithmic errors, security risks, control risks like rogue outcomes and unintended consequences, economic risks, ethical risks, and societal risks like unfair outcomes for underprivileged or marginalized communities. For companies, this often means avoiding significant _costs and fines_.

- **Transparency may improve your algorithmic systems.** Transparency can increase trust among all the stakeholders of an system, which may lead to better outcomes for that system.

- **Implementing transparency will soon likely be law.** Governments around the world have begun to draft and enact legislation regulating the transparency of algorithmic systems, including two major proposals in both the <a href="https://artificialintelligenceact.eu/" target="_blank">EU</a> and <a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/" target="_blank">US</a>.

<br>

### "Black-box" algorithms

Advancements in AI have made algorithms considerably more complex. These complex, nuanced algorithms that are not easily understood by human users are often referred to as **black-box** algorithms (because one cannot see inside). 

> **Black-box** is a blanket term used to describe __any system__ in which a human cannot see the inner workings of the algorithm. Algorithms commonly designated as black-boxes are _nueral networks (used for deep learning), gradient boosted-models, and forest-based models._

Black-box are said to be _opaque_ (i.e. the opposite of transparent). But notably, in the past decade, **researchers and practitioners have made significant developments in "opening-up" black-box systems.** There are many powerful, free, and easy-to-use tools that can be used to gain insight into how underlying black-box algorithms work. The most popular tool is called _SHAP_, or SHapley Additive exPlanations <a href="https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf" target="_blank">(Lundberg and Lee 2017)</a>. SHAP is very simple to use and can often be understood by laypersons with just a little training. 

<br>

### Who is transparency for?

Since algorithmic transparency is all about the _human_ understanding of an algorithm, it's important to identify who it is for. Algorithmic transparency can be important for many people both internally to and externally of an organization. There are five main groups of people impacted by algorithms <a href="https://www.cambridge.org/core/journals/data-and-policy/article/think-about-the-stakeholders-first-toward-an-algorithmic-transparency-playbook-for-regulatory-compliance/10D7F194DB250DDF3A30471B5CEB9326" target="_blank">(Bell, Nov, Stoyanovich 2023)</a>:


| **Stakeholder**         | **Definition**                                                                                                                                                                        |
|-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Practitioners**       | The technical practitioners that are developing, implementing, and maintaining algorithmic systems. They include _data scientists, engineers, programmers, developers, and analysts._ |
| **Managers**            | The individuals at many different levels in an organization that oversee algorithmic decision-making tools. They include _project managers, business developers, and executives._     |
| **Affected persons**    | The people who are impacted by the algorithm. For example, if an algorithm is being used to assess job applicants, the job applicants are the affected persons.                       |
| **Humans-in-the-loop**  | The individuals who are responsible for using the algorithm. Humans-in-the-loop may also be called _algorithm managers or users._                                                     |
| **Compliance officers** | Persons who oversee the legal compliance of algorithms, and may include _auditors and policymakers._                                                                                  |

<!--
- **Practitioners:** The technical practitioners that are developing, implementing, and maintaining algorithmic systems. They include _data scientists, engineers, programmers, developers, and analysts._
- **Managers:** Those that oversee projects using algorithmic tools. They exist at many many different levels in an organization, and include _project managers, business developers, procurement manager, and executives_.
- **Affected persons:** The people who are impacted by the algorithm. For example, if an algorithm is being used to assess job applicants, the job applicants are the affected persons.
- **Humans-in-the-loop:** The individuals who are responsible for _using the algorithm._ Humans-in-the-loop may also be called algorithm managers or users.
- **Regulators:** Persons who oversee the legal compliance of algorithms, and may include also include _auditors, compliance officers, and policymakers_.
-->

> _Exercise:_ Recall the examples of algorithmic transparency we have discussed thus far in this course. Can you identify some of the relevant transparency stakeholders for those examples?

<br>

### How do people use transparency?

There are a diverse set of goals or reasons that a stakeholder may want transparency for an algorithmic system. Below we group goals into six different categories:

| **Goal**                 | **Definition**                                                                        | **Example**                                                                                                 |
|----------------------|-----------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|
| Validity             | Making sure the system is constructed correctly, debugging a system               | The programmers, engineers, and managers may use transparency to ensure the system is valid and correct |
| Trust                | Knowing "how often the system is right"                                           | A policymaker or auditor may use transparency to gain trust in the ADS                                  |
| Learning and Support | Increasing general understanding about how an algorithm reaches a decision        | A doctor may use transparency to better understand an algorithms predicted diagnosis of a patient       |
| Recourse             | Allowing affected persons to take action against a decision                       | An individual may use transparency about an algorithm to appeal a loan rejection                        |
| Fairness             | Ensuring that an algorithm is ** making decision biased against a minority group | An auditor may use transparency to make sure that an algorithm is ** biased                            |
| Privacy              | Ensuring that an algorithm respects the data privacy of individuals               | An auditor may use transparency to make sure that an algorithm is ** violating data privacy laws       |

One critical goal for transparency is the idea of **algorithmic recourse** (sometimes called **redress**), which is the ability of a person affected by the outcome of an algorithm to see why that decision was made and what they can do to change that outcome. For example, if an algorithm is used to determine whether or not an individual is accepted or rejected for a loan, that individual should be able to see why that decision was made so they can take actions to change the decision in the future (ex. improve credit score).

<br>

### Case-study: AI in journalism



<!--
### Is algoirthmic transparency easy to do?

The short answer is yes. For any algorithm, there are easy first steps that can be taken to move from an algorithm being to _completely opaque_ to _at least slightly tranparent._

> **The Easiset Fist-Step for Transparency** <br><br> A fundamental first step in algorithmic transparency can be be _as simple as telling people that you are using an algorithm_. Many organizations either take this fact for granted, or deliberately keep this fact hidden from the public. Do not underestimate the value of simply disclosing the use of an algorithmic system, and telling people what attributes, factors, or inputs the algorithm uses.

The long answer is that, while it can be easy to create basic transparency features, it takes more effort to create robust and lasting transparency. One should be thoughtful about _how_, _why_ and _to what end_ transparency is implemented --- all of which will be discussed extensively in this course. Importantly, we believe that the organizational and societal benefits of algorithmic transparency greatly justify the efforts of implementing it correctly.

<br>

### How is algorithmic transparency different from fairness or bias?

Algorithmic transparency is often confused with ideas like **fairnessand bias** --- but importantly, they are not the same thing.

_Algorithmic transparency_ is about the visibility of information about a system. In contrast, _algorithmic fairness_ is concerned with addressing societal biases that are present in an algorithmic system. While fairness and transparency can be related (for example, visibility into an algorithmic system may reveal its biases), they are actually independent. Ensuring transparency does not ensure fairness, and vice versa. Instead, they are connected in-so-far as it is infinitely easier to detect fairness issues in algorithms that are transparent.
-->