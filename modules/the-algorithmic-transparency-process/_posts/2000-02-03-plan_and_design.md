---
title: Plan and design for stakeholders and their goals (part 1)
---

## Step 2: Plan & design transparency for your algorithms

Once you have identified all the algorithmic decision-making systems within your organization, it is time to begin planning and designing how transparency will be used in those algorithms. This second step is broken up into 4 sub-steps and is based on our **stakeholder-first approach** to developing transparency that begins with thinking about algorithmic stakeholders first, and ends with creating transparency features for your algorithms that meet stakeholder needs.

> A _transparency feature_ is any artificat accompayning an algorithm that helps increase its ability to be understood by a human user. Some examples include a dashboard, graph, report, paper hand-out, or even an informational pop-up window on a web page.

<br>

### Step 2A: Consider all the relevant stakeholders of each algorithm.

In the introduction to this playbook, we discussed several important stakeholders of algorithmic decision-making systems. These included **managers** within an organization, the **humans-in-the-loop** who actually use the systems, and the **affected persons** who are impacted by the outcome of the stakeholder. Notably, stakeholders may be both internal and external to your organization.

Humans-in-the-loop are the people who are actually responsible for using the algorithmic tool. These are often distinct from those developing the algorithm, and some examples include an underwriter using an algorithm to determine if loan applicants should be accepted or rejected, or hospital staff using an algorithm to predict the risk a patient will develop a disease.

Importantly, not every stakeholder has the same needs when it comes to algorithmic transparency, and so those implementing transparency should be thoughtful about each type of stakeholder. There are 5 categories of stakeholders that you should consider (note that not every algorithm will have all 5 stakeholders):

| **Stakeholder**         | **Definition**                                                                                                                                                                        |
|-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Practitioners**       | The technical practitioners that are developing, implementing, and maintaining algorithmic systems. They include _data scientists, engineers, programmers, developers, and analysts._ |
| **Managers**            | The individuals at many different levels in an organization that oversee algorithmic decision-making tools. They include _project managers, business developers, and executives._     |
| **Affected persons**    | The people who are impacted by the algorithm. For example, if an algorithm is being used to assess job applicants, the job applicants are the affected persons.                       |
| **Humans-in-the-loop**  | The individuals who are responsible for using the algorithm. Humans-in-the-loop may also be called _algorithm managers or users._                                                     |
| **Compliance officers** | Persons who oversee the legal compliance of algorithms, and may include _auditors and policymakers._                                                                                  |

For each algorithm you identified during the inventory phase, you should consider **each of the stakeholder categories above.** Furthermore, you may want to prioritize your list of stakeholders and weigh their needs differently. For example, it may be more meaningful to meet the transparency needs of affected persons over managers or compliance officers.

> **DELIVERABLE:** A list of stakeholders for each algorithmic decision-making system in your organization.

<br>

### Step 2B: Create a list of the potential goals of each stakeholder.

After you have determined the stakeholders of each system in your organization, you should consider their goals for transparency. Remember that transparency goals always start with a stakeholder since transparency is always ultimately intended for a human audience.

Broadly, the goals of transparency are ensuring validity, building trust, assisting in learning and support, supporting recourse, and ensuring fairness and privacy. These goals are below:

| Goal                 | Definition                                                                        | Example                                                                                                 |
|----------------------|-----------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|
| Validity             | Making sure the system is constructed correctly, debugging a system               | The programmers, engineers, and managers may use transparency to ensure the system is valid and correct |
| Trust                | Knowing "how often the system is right"                                           | A policymaker or auditor may use transparency to gain trust in the ADS                                  |
| Learning and Support | Increasing general understanding about how an algorithm reaches a decision        | A doctor may use transparency to better understand an algorithms predicted diagnosis of a patient       |
| Recourse             | Allowing affected persons to take action against a decision                       | An individual may use transparency about an algorithm to appeal a loan rejection                        |
| Fairness             | Ensuring that an algorithm is not making decision biased against a minority group | An auditor may use transparency to make sure that an algorithm is not biased                            |
| Privacy              | Ensuring that an algorithm respects the data privacy of individuals               | An auditor may use transparency to make sure that an algorithm is not violating data privacy laws       |

One critical goal for transparency is the idea of **recourse** (sometimes called redress), which is the ability of a person affected by the outcome of an algorithm to see why that decision was made and what they can do to change that outcome. For example, if an algorithm is used to determine whether or not an individual is accepted or rejected for a loan, that individual should be able to see why that decision was made so they can take actions to change the decision in the future (ex. improve credit score). Notably, recourse has become a popular idea among policymakers, and there is proposed legislation in both the United States and Europe that would mandate designing algorithms that allow recourse for affected persons.

When possible, ideas from **participatory design** should always be used to determine stakeholder goals. Participatory design, also called _co-operative design or co-design_, is an approach to design wherein those stakeholders identified earlier are _actively involved in the design process_to help ensure the result meets their needs. In one promising example, designers used participatory design to successfully create better explanations about an algorithmic tool in the field of communal energy accounting by having conversations with directly with the tool's users.

> **DELIVERABLE:** A list of goals for each stakeholder of each algorithmic decision-making system in your organization. At this point, your running inventory might be quite long&mdash;but you can be assured that you have thoughtfully considered all the important aspects of algorithmic transparency.