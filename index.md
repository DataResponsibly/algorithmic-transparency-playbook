---
layout: index
published: true
---

Welcome to 2033, the year when AI, while not yet sentient, can finally be considered responsible. Only systems that work well, improve efficiency, are fair, law abiding, and transparent are in use today. It's AI nirvana. You ask yourself: _"How did we get here?"_

You may have played a major role! As more organizations use algorithmic systems, there is a **need for practitioners, industry leaders, managers, and executives to take part in making AI responsible.** In this course, we provide a playbook, detailing how to influence change and implement algorithmic transparency for your organization's algorithmic systems. 

<hr>

Those who complete this course will learn everything they need to know about algorithmic transparency, and how one can help influence change within their organization towards having more open, and accountable systems. The course also includes a case study game where you will get to explore the tension between different key stakeholders vying for and against algorithmic transparency!

To get started, proceed to the first module [All-About-Transparency](https://dataresponsibly.github.io/algorithmic-transparency-playbook/modules/all-about-transparency/index/).

<hr>

This course is [published](https://doi.org/3544549.3574169) in the 2023 ACM CHI Conference on Human Factors in Computing Systems proceedings.

This research was supported in part by NSF Awards No. 1934464, 1922658, 1916505, 1928614, and 2129076.